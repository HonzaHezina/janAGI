from mcp_agent.agents.agent import Agent
from typing import Dict, Optional
import asyncio

# Prefer per-agent runner and allow agent-specific model/provider via agent_config.
# Keep a fallback import path for running from repository root or examples.
try:
    from mcp_agent.llm_mcp_app.agent_runner import AgentRunner
    from mcp_agent.llm_mcp_app.providers import get_provider
    from mcp_agent.llm_mcp_app.models import Message
except ImportError:
    from llm_mcp_app.agent_runner import AgentRunner  # type: ignore
    from llm_mcp_app.providers import get_provider  # type: ignore
    from llm_mcp_app.models import Message  # type: ignore

def _local_generate_template(task: str) -> str:
    """
    Locally generate a simple agent.yaml and a Python skeleton for a new agent.
    The returned value is plain text with YAML first, then '---', then Python code.
    """
    # Example YAML (constructed manually to avoid new dependencies)
    yaml = f"""name: example_agent
description: |
  Example agent generated for task:
  {task}
model: gpt-4
provider: openai
prompt_template: |
  {{prompt}}
permissions: []
timeout: 60
entrypoint: main.py
"""
    # Minimal Python skeleton for an agent following project conventions
    python_skel = '''from mcp_agent.agents.agent import Agent
from typing import Dict, Optional
import asyncio

try:
    from mcp_agent.llm_mcp_app.agent_runner import AgentRunner
except ImportError:
    from llm_mcp_app.agent_runner import AgentRunner  # type: ignore

def run(task: str, agent_config: Optional[Dict] = None) -> Dict[str, str]:
    """
    Run the agent. Uses AgentRunner when agent_config is provided,
    otherwise returns a simple placeholder response.
    """
    if agent_config:
        runner = AgentRunner(agent_config)
        try:
            result = asyncio.run(runner.run(task))
            if isinstance(result, dict):
                return {"result": result.get("result", str(result))}
            return {"result": str(result)}
        except Exception:
            return {"result": "<error from AgentRunner>"}
    # Fallback/local hard-coded behaviour
    return {"result": f"<skeleton response for: {task}>"}

def generate(task: str, agent_config: Optional[Dict] = None) -> str:
    result = run(task, agent_config)
    if isinstance(result, dict):
        return result.get("result", str(result))
    return str(result)

def get_agent(agent_config: Optional[Dict] = None) -> Agent:
    """
    Return an Agent instance exposing a generate(task) function.
    Captures agent_config in the closure to respect loader behaviour.
    """
    def _generate(task: str) -> str:
        return generate(task, agent_config)

    instruction = "Skeleton agent generated by agent_factory."
    return Agent(name="example_agent", instruction=instruction, functions=[_generate])

if __name__ == "__main__":
    a = get_agent()
    print("Agent created:", a.name)
    print("Instruction:", a.instruction)
    print("\\nTemplate output (YAML + --- + Python skeleton):")
    print(_local_generate_template("sample task"))
'''
    return yaml + "\n---\n" + python_skel

def run(task: str, agent_config: Optional[Dict] = None) -> Dict[str, str]:
    """
    Run wrapper for compatibility with loader expectations.
    If agent_config is provided, delegate to AgentRunner for possible LLM-based generation.
    Otherwise use a local generator.
    """
    if agent_config:
        runner = AgentRunner(agent_config)
        try:
            result = asyncio.run(runner.run(task))
            if isinstance(result, dict):
                return {"result": result.get("result", str(result))}
            return {"result": str(result)}
        except Exception:
            # Fallback to local generator on error
            return {"result": _local_generate_template(task)}
    return {"result": _local_generate_template(task)}

def generate_template(task: str, agent_config: Optional[Dict] = None) -> str:
    """
    Public function exported by the agent that returns a plain-text template
    containing YAML and a Python skeleton separated by '---'.
    Respects agent_config/AgentRunner if provided.
    """
    if agent_config:
        # Prefer using AgentRunner to allow LLM-based template generation/validation.
        try:
            runner = AgentRunner(agent_config)
            out = asyncio.run(runner.run(task))
            if isinstance(out, dict):
                # Expect runner to return plain text under 'result'
                return out.get("result", str(out))
            return str(out)
        except Exception:
            # On any failure, fall back to the local generator
            return _local_generate_template(task)
    return _local_generate_template(task)

def get_agent(agent_config: Optional[Dict] = None) -> Agent:
    """
    Exported factory function compatible with the loader. Captures optional agent_config.
    """
    def _generate_template(task: str) -> str:
        return generate_template(task, agent_config)

    instruction = "Meta-agent that generates agent.yaml + main.py skeleton separated by '---'."
    return Agent(name="agent_factory", instruction=instruction, functions=[_generate_template])